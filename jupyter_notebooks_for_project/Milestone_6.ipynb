{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict as OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderedDict = {'a': 1, 'b': 2, 'c': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "print(OrderedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for x in range(6):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for x in range(2, 6):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in range(5 -1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in range(5 -1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.input_layer(9, hidden_layer_width)\n",
    "self.linear_layer_1(hidden_layer_width, hidden_layer_width)\n",
    "self.linear_layer_2(hidden_layer_width, hidden_layer_width)\n",
    "self.linear_layer_3(hidden_layer_width, hidden_layer_width)\n",
    "self.linear_layer_4(hidden_layer_width, hidden_layer_width)\n",
    "self.output_layer(hidden_layer_width, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, X):        \n",
    "        X= self.linear_layer(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.linear_layer_2(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.linear_layer_3(X)\n",
    "        X = F.relu(X)\n",
    "        X= self.linear_layer_4(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.linear_layer_5(X)\n",
    "        X = F.relu(X)\n",
    "        X= self.linear_layer_6\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Neural Network.\n",
    "\n",
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        hidden_layer_width = config['hidden_layer_width']\n",
    "        depth = config['depth']\n",
    "        print(hidden_layer_width)\n",
    "        print(depth)\n",
    "        input_nodes = 9\n",
    "        output_nodes = 1\n",
    "        self.linear_layers = []\n",
    "        self.input_layer = torch.nn.Linear(input_nodes, hidden_layer_width)\n",
    "        \n",
    "        for hidden_layer in range(depth -1):\n",
    "            self.linear_layers.append(torch.nn.Sequential(torch.nn.Linear(hidden_layer_width, hidden_layer_width)))\n",
    "            self.linear_layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        self.linear_layers = torch.nn.Sequential(*self.linear_layers)\n",
    "        # print(self.linear_layers)\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(hidden_layer_width, output_nodes)\n",
    "        \n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.input_layer(X)\n",
    "        X = self.linear_layers(X)\n",
    "        X = self.output_layer(X)\n",
    "        print(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "Adam_hyperparameters = {'optimiser': ['Adam'], 'learning_rate': [0.001, 0.0001], 'amsgrad': [True, False], 'hidden layer width': [5], 'depth': [3] }\n",
    "Adadelta_hyperparameters = {'optimiser': ['Adadelta'], 'learning_rate': [1.0, 0.001, 0.0001], 'maximise': [True, False], 'hidden layer width': [5], 'depth': [3]}\n",
    "SGD_hyperparameters = {'optimiser': ['SGD'], 'learning_rate': [1.0, 0.001, 0.0001], 'weight decay': [0.01, 0.02], 'momentum': [0.1], 'hidden layer width': [5], 'depth': [3]}\n",
    "\n",
    "optimiser_list = [Adam_hyperparameters, Adadelta_hyperparameters, SGD_hyperparameters]\n",
    "nn_configs = []\n",
    "\n",
    "for optimiser in optimiser_list:\n",
    "    keys, values = zip(*optimiser.items())\n",
    "    hyperparameters_dict= [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    nn_configs.append(hyperparameters_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimiser': 'Adam', 'learning_rate': 0.001, 'amsgrad': True, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adam', 'learning_rate': 0.001, 'amsgrad': False, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adam', 'learning_rate': 0.0001, 'amsgrad': True, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adam', 'learning_rate': 0.0001, 'amsgrad': False, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adadelta', 'learning_rate': 1.0, 'maximise': True, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adadelta', 'learning_rate': 1.0, 'maximise': False, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adadelta', 'learning_rate': 0.001, 'maximise': True, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adadelta', 'learning_rate': 0.001, 'maximise': False, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adadelta', 'learning_rate': 0.0001, 'maximise': True, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'Adadelta', 'learning_rate': 0.0001, 'maximise': False, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'SGD', 'learning_rate': 1.0, 'weight decay': 0.01, 'momentum': 0.1, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'SGD', 'learning_rate': 1.0, 'weight decay': 0.02, 'momentum': 0.1, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'SGD', 'learning_rate': 0.001, 'weight decay': 0.01, 'momentum': 0.1, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'SGD', 'learning_rate': 0.001, 'weight decay': 0.02, 'momentum': 0.1, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'SGD', 'learning_rate': 0.0001, 'weight decay': 0.01, 'momentum': 0.1, 'hidden layer width': 5, 'depth': 3}\n",
      "{'optimiser': 'SGD', 'learning_rate': 0.0001, 'weight decay': 0.02, 'momentum': 0.1, 'hidden layer width': 5, 'depth': 3}\n"
     ]
    }
   ],
   "source": [
    "for nn_config in nn_configs:\n",
    "    for config in nn_config:\n",
    "        print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterators = itertools.cycle(nn_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'optimiser': 'Adam', 'learning_rate': 0.001, 'amsgrad': True, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adam', 'learning_rate': 0.001, 'amsgrad': False, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adam', 'learning_rate': 0.0001, 'amsgrad': True, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adam', 'learning_rate': 0.0001, 'amsgrad': False, 'hidden layer width': 5, 'depth': 3}]\n",
      "[{'optimiser': 'Adadelta', 'learning_rate': 1.0, 'maximise': True, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adadelta', 'learning_rate': 1.0, 'maximise': False, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adadelta', 'learning_rate': 0.001, 'maximise': True, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adadelta', 'learning_rate': 0.001, 'maximise': False, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adadelta', 'learning_rate': 0.0001, 'maximise': True, 'hidden layer width': 5, 'depth': 3}, {'optimiser': 'Adadelta', 'learning_rate': 0.0001, 'maximise': False, 'hidden layer width': 5, 'depth': 3}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(next(iterators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "Adam_hyperparameters = {'optimiser': ['Adam'], 'learning_rate': [0.001, 0.0001], 'amsgrad': [True, False] }\n",
    "\n",
    "nn_configs = list(product(*Adam_hyperparameters.values()))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Adam', 0.001, True),\n",
       " ('Adam', 0.001, False),\n",
       " ('Adam', 0.0001, True),\n",
       " ('Adam', 0.0001, False)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "Adam_hyperparameters = {'optimiser': ['Adam'], 'learning_rate': [0.001, 0.0001], 'amsgrad': [True, False], 'hidden layer width': [5], 'depth': [3] }\n",
    "keys, values = zip(*Adam_hyperparameters.items())\n",
    "Adam_hyperparameters_dict= [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "\n",
    "Adadelta_hyperparameters = {'optimiser': ['Adadelta'], 'learning_rate': [1.0, 0.001, 0.0001], 'maximise': [True, False], 'hidden layer width': [5], 'depth': [3]}\n",
    "\n",
    "\n",
    "SGD_hyperparameters = {'optimiser': ['SGD'], 'learning_rate': [1.0, 0.001, 0.0001], 'weight decay': [0.01, 0.02], 'momentum': [0.1], 'hidden layer width': [5], 'depth': [3]}\n",
    "\n",
    "optimiser_list = [Adam_hyperparameters, Adadelta_hyperparameters, SGD_hyperparameters]\n",
    "nn_configs = []\n",
    "\n",
    "for optimiser in optimiser_list:\n",
    "    keys, values = zip(*optimiser.items())\n",
    "    hyperparameters_dict= [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    nn_configs.append(hyperparameters_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m R2_list \u001b[39m=\u001b[39m [tensor(\u001b[39m-\u001b[39m\u001b[39m0.3795\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m0.2179\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m4.6174\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m2.0276\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m1.9410\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m1.8206\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m13.8644\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m9.4723\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m2.3412\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m4.6628\u001b[39m), tensor(nan), tensor(nan), tensor(\u001b[39m-\u001b[39m\u001b[39m0.1548\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m0.0641\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m0.7319\u001b[39m), tensor(\u001b[39m-\u001b[39m\u001b[39m1.9359\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "R2_list = [tensor(-0.3795), tensor(-0.2179), tensor(-4.6174), tensor(-2.0276), tensor(-1.9410), tensor(-1.8206), tensor(-13.8644), tensor(-9.4723), tensor(-2.3412), tensor(-4.6628), tensor(nan), tensor(nan), tensor(-0.1548), tensor(-0.0641), tensor(-0.7319), tensor(-1.9359)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
